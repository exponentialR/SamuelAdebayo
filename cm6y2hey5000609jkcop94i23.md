---
title: "Can AI see Alzheimer's before Symptoms appear?"
seoTitle: "Predicting Alzheimer’s Disease with AI: A Hybrid CNN Approach"
seoDescription: "AI-powered early Alzheimer’s detection using a hybrid 2D-3D CNN model. Discover how deep learning and medical imaging improve diagnosis accuracy."
datePublished: Sun Feb 09 2025 20:18:45 GMT+0000 (Coordinated Universal Time)
cuid: cm6y2hey5000609jkcop94i23
slug: can-ai-see-alzheimers-before-symptoms-appear
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1739131906552/da1c0fed-0ad6-49cb-8fcd-d5c35c3d32cf.png
ogImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1739132127342/406d8152-a125-45d5-9ef7-21ea6a35bde9.png
tags: image-processing, computer-vision, deep-learning, cnn, aiforgood, neuralnetworks, convolutionalneuralnetworks, medicalai, 2dcnn, 3dcnn

---

One of the interesting research projects I collaborated on with colleagues in China last year was using vision to predict the tendency of developing Alzheimer’s disease. We used images from diverse clinical datasets, which gave us a base and provided a rich variety of cases. However, the images when marred with uncertainties, often arising from imaging artefacts, variations in acquisition protocols, and intrinsic noise, the prediction became less reliable, hence complicating the analysis.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1739132040489/4877f9e3-74ff-4a81-acbe-4df0347e298c.gif align="center")

To address this, we proposed a hybrid approach that leverages the strengths of both 2D and 3D convolutional neural networks. In our approach, we engineered the 2D CNN component to capture fine-grained texture details, while the 3D CNN extracts essential volumetric context. A key innovation in our methodology was the creation of virtual augmented slices to account for the additional channel in 3D to encode a series of uncertainties directly within our model. This approach enables us to better represent the ambiguities inherent in the data and to perhaps catch uncertainties that may not be present now in the model but at inference. This led us to achieve better results compared to existing methods.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1739131574186/5206102b-d9c1-4b89-ae7c-71d4c870320f.png align="center")

You can read the preprint version of our paper here: [https://arxiv.org/pdf/2410.02714](https://arxiv.org/pdf/2410.02714)  
Code available on request.

Our current open question is: how can we best leverage multi-modal data to enhance our predictive models further? For instance, integrating additional imaging modalities such as PET scans or incorporating non-imaging biomarkers, like genetic and clinical data, could offer a more holistic view of disease progression. This fusion of diverse data sources might refine early detection strategies and pave the way for more personalised interventions.